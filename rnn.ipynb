{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = tf.keras.datasets.imdb.load_data(num_words=1000)\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train_imdb])\n",
    "x_test_imdb = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test_imdb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 26441.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data average document length = 238.71364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_doc_length = 0\n",
    "for doc in tqdm(x_train_imdb):\n",
    "  tokens = str(doc).split()\n",
    "  train_doc_length += len(tokens)\n",
    "\n",
    "print('\\nTraining data average document length =', (train_doc_length \n",
    "                                                  / len(x_train_imdb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100000\n",
    "SEQ_MAX_LENGTH = 250\n",
    "vectorizer = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE,output_mode='int',ngrams=1, name='vector_text',output_sequence_length=SEQ_MAX_LENGTH)\n",
    "with tf.device('/CPU:0'):\n",
    "  vectorizer.adapt(x_train_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(1,), dtype=tf.string),\n",
    "      vectorizer\n",
    "])\n",
    "vector_model.predict([['awesome movie']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04252988,  0.04213793,  0.00226843, -0.00648656, -0.04334333],\n",
       "       [-0.0170845 , -0.01579864,  0.00528366, -0.02621027, -0.00614031],\n",
       "       [ 0.03473804, -0.04966135,  0.00981089, -0.01406177,  0.01161015]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_embeddings = tf.keras.layers.Embedding(1000, 5)\n",
    "dummy_embeddings(tf.constant([1, 2, 3])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.9.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from fasttext) (58.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from fasttext) (1.22.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from fasttext) (2.10.3)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3.1\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'gzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%pip install fasttext\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
    "!gzip -d cc.en.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cc.en.300.bin cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive\\Desktop\\3year\\texniti noimosini\\ask2\\rnn.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Desktop/3year/texniti%20noimosini/ask2/rnn.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfasttext\u001b[39;00m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Desktop/3year/texniti%20noimosini/ask2/rnn.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fasttext_model \u001b[39m=\u001b[39m fasttext\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mcc.en.300.bin\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Desktop/3year/texniti%20noimosini/ask2/rnn.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m embedding_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(vectorizer\u001b[39m.\u001b[39mget_vocabulary()), \u001b[39m300\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Desktop/3year/texniti%20noimosini/ask2/rnn.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, word \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(vectorizer\u001b[39m.\u001b[39mget_vocabulary()):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\fasttext\\FastText.py:441\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m eprint(\u001b[39m\"\u001b[39m\u001b[39mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 441\u001b[0m \u001b[39mreturn\u001b[39;00m _FastText(model_path\u001b[39m=\u001b[39;49mpath)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\fasttext\\FastText.py:98\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[1;34m(self, model_path, args)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fasttext\u001b[39m.\u001b[39mfasttext()\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m model_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf\u001b[39m.\u001b[39;49mloadModel(model_path)\n\u001b[0;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_words \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cc.en.300.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "import fasttext \n",
    "\n",
    "fasttext_model = fasttext.load_model('cc.en.300.bin')\n",
    "embedding_matrix = np.zeros(shape=(len(vectorizer.get_vocabulary()), 300))\n",
    "\n",
    "for i, word in enumerate(vectorizer.get_vocabulary()):\n",
    "  embedding_matrix[i] = fasttext_model.get_word_vector(word=word)\n",
    "\n",
    "del fasttext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image \n",
    "\n",
    "def get_fasttext_bigru(num_layers=1, h_size=64):\n",
    "  inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='txt_input')\n",
    "  x = vectorizer(inputs)\n",
    "  x = tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()),\n",
    "                                output_dim=300, name='word_embeddings',\n",
    "                                trainable=False, weights=[embedding_matrix],\n",
    "                                mask_zero=True)(x)\n",
    "\n",
    "  # x = tf.keras.layers.Dense(units=h_size, activation='relu', name='dense')(x)\n",
    "  x = tf.keras.layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "  for n in range(num_layers):\n",
    "    if n != num_layers - 1:\n",
    "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=h_size, \n",
    "                              name=f'bigru_cell_{n}', \n",
    "                              return_sequences=True,\n",
    "                              dropout=0.2))(x)\n",
    "    else:\n",
    "      x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=h_size, \n",
    "                                        name=f'bigru_cell_{n}',\n",
    "                                        dropout=0.2))(x)\n",
    "\n",
    "  x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "  o = tf.keras.layers.Dense(units=1, activation='sigmoid', name='lr')(x)\n",
    "  return tf.keras.models.Model(inputs=inputs, outputs=o, name='simple_rnn')\n",
    "\n",
    "imdb_fasttext_bigru = get_fasttext_bigru()\n",
    "print(imdb_fasttext_bigru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_fasttext_bigru.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "                            optimizer=tf.keras.optimizers.Adam(),\n",
    "                            metrics=['binary_accuracy'])\n",
    "imdb_hist = imdb_fasttext_bigru.fit(x=x_train_imdb, y=y_train_imdb,\n",
    "                        epochs=10, verbose=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb_fasttext_bigru.evaluate(x_test_imdb, y_test_imdb))\n",
    "predictions = imdb_fasttext_bigru.evaluate(x_test_imdb, y_test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "y = np.array([0.3473,0.3427,0.3338,0.3259,0.3189,0.3095,0.3039,0.2946,0.2860,0.2812])\n",
    "x = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "ax.grid(True, linestyle='-.')\n",
    "\n",
    "ax.tick_params(labelcolor='r', labelsize='medium', width=4,)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(imdb_hist.history).plot(figsize=(8,5))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c880bf50398c9e6ebbd48c247ea31cff5c6f8ce48b9cfb1b78e929d6cc40437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
